{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "66abc7c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import string \n",
    "import nltk\n",
    "from nltk.tokenize import TreebankWordTokenizer\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "\n",
    "\n",
    "REMOVE_PUNCTUATION_TABLE = str.maketrans({x: None for x in string.punctuation})\n",
    "TOKENIZER = TreebankWordTokenizer()\n",
    "STEMMER = PorterStemmer()\n",
    "\n",
    "def tokenize_and_stem(s):\n",
    "    return [STEMMER.stem(t) for t \n",
    "            in TOKENIZER.tokenize(s.translate(REMOVE_PUNCTUATION_TABLE))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "03cb8c36",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = []\n",
    "#open text file in read mode\n",
    "for num in range(1 , 101):\n",
    "    text_file = open(\"archive/business/business_\" + str(num) + \".txt\", \"r\")\n",
    "    #read whole file to a string\n",
    "    data = text_file.read().replace('\\n',' ')\n",
    "    #close file\n",
    "    text_file.close()\n",
    "    docs.append(data);\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "8d4bfad6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:528: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['abov', 'afterward', 'alon', 'alreadi', 'alway', 'ani', 'anoth', 'anyon', 'anyth', 'anywher', 'becam', 'becaus', 'becom', 'befor', 'besid', 'cri', 'describ', 'dure', 'els', 'elsewher', 'empti', 'everi', 'everyon', 'everyth', 'everywher', 'fifti', 'formerli', 'forti', 'ha', 'henc', 'hereaft', 'herebi', 'hi', 'howev', 'hundr', 'inde', 'latterli', 'mani', 'meanwhil', 'moreov', 'mostli', 'nobodi', 'noon', 'noth', 'nowher', 'onc', 'onli', 'otherwis', 'ourselv', 'perhap', 'pleas', 'seriou', 'sever', 'sinc', 'sincer', 'sixti', 'someon', 'someth', 'sometim', 'somewher', 'themselv', 'thenc', 'thereaft', 'therebi', 'therefor', 'thi', 'thu', 'togeth', 'twelv', 'twenti', 'veri', 'wa', 'whatev', 'whenc', 'whenev', 'wherea', 'whereaft', 'wherebi', 'wherev', 'whi', 'yourselv'] not in stop_words.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "vectorizer = TfidfVectorizer(tokenizer=tokenize_and_stem, stop_words='english')\n",
    "vectorizer.fit(docs)\n",
    "docs_vec = vectorizer.transform(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "81ab37fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = 'Industrial output falls in Japan  Japanese industrial'\n",
    "query_vector = vectorizer.transform([query])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "127f136c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "doc_vectors = vectorizer.transform(docs)\n",
    "similarity = cosine_similarity(query_vector, doc_vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "2209ee51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1, 0.0], [2, 0.1742484008668953], [3, 0.0], [4, 0.026776598006371596], [5, 0.09242787376436135], [6, 0.01003279932447327], [7, 0.0], [8, 0.0], [9, 0.036964343459406385], [10, 0.0], [11, 0.014097197821311422], [12, 0.00980830357561132], [13, 0.32340527048097106], [14, 0.0], [15, 0.05874255298632514], [16, 0.02290423393638406], [17, 0.0], [18, 0.0734118489185981], [19, 0.0], [20, 0.021790755304662058], [21, 0.0], [22, 0.0], [23, 0.01855423292698453], [24, 0.0], [25, 0.0], [26, 0.10626330835933472], [27, 0.0], [28, 0.04188519939530096], [29, 0.016283397048328093], [30, 0.014940678291405388], [31, 0.0], [32, 0.03825148766413921], [33, 0.029771105220749935], [34, 0.0], [35, 0.03474444587731039], [36, 0.0], [37, 0.0], [38, 0.0107512102317573], [39, 0.03272415197791791], [40, 0.04274007060099563], [41, 0.008339787336425868], [42, 0.06523361506981556], [43, 0.06456145652832253], [44, 0.0718129201952091], [45, 0.0], [46, 0.0], [47, 0.0], [48, 0.22858209077708355], [49, 0.0], [50, 0.0746432837272482], [51, 0.2896896466976147], [52, 0.02875624185606008], [53, 0.02276350267289312], [54, 0.04099970999194341], [55, 0.04792120338678286], [56, 0.038419708694368], [57, 0.02314153090270996], [58, 0.0], [59, 0.0], [60, 0.025506734601298067], [61, 0.009980707128183358], [62, 0.0], [63, 0.02072357465345583], [64, 0.0], [65, 0.01938015376792324], [66, 0.0], [67, 0.04308299225619573], [68, 0.0], [69, 0.0], [70, 0.0833831411688578], [71, 0.0], [72, 0.0], [73, 0.1691239130668874], [74, 0.03516923213492263], [75, 0.0], [76, 0.0], [77, 0.0], [78, 0.0], [79, 0.0], [80, 0.0], [81, 0.018414408318769053], [82, 0.02276350267289312], [83, 0.0], [84, 0.04778086744774244], [85, 0.026506672551624012], [86, 0.0], [87, 0.0], [88, 0.0], [89, 0.013771817205825222], [90, 0.0], [91, 0.0062365846796774245], [92, 0.016214393555048036], [93, 0.0], [94, 0.2213944349675946], [95, 0.03619371899705285], [96, 0.3627963538030673], [97, 0.0], [98, 0.0], [99, 0.0], [100, 0.014859461098840109]]\n",
      "[[1, 0.0], [3, 0.0], [7, 0.0], [8, 0.0], [10, 0.0], [14, 0.0], [17, 0.0], [19, 0.0], [21, 0.0], [22, 0.0], [24, 0.0], [25, 0.0], [27, 0.0], [31, 0.0], [34, 0.0], [36, 0.0], [37, 0.0], [45, 0.0], [46, 0.0], [47, 0.0], [49, 0.0], [58, 0.0], [59, 0.0], [62, 0.0], [64, 0.0], [66, 0.0], [68, 0.0], [69, 0.0], [71, 0.0], [72, 0.0], [75, 0.0], [76, 0.0], [77, 0.0], [78, 0.0], [79, 0.0], [80, 0.0], [83, 0.0], [86, 0.0], [87, 0.0], [88, 0.0], [90, 0.0], [93, 0.0], [97, 0.0], [98, 0.0], [99, 0.0], [91, 0.0062365846796774245], [41, 0.008339787336425868], [12, 0.00980830357561132], [61, 0.009980707128183358], [6, 0.01003279932447327], [38, 0.0107512102317573], [89, 0.013771817205825222], [11, 0.014097197821311422], [100, 0.014859461098840109], [30, 0.014940678291405388], [92, 0.016214393555048036], [29, 0.016283397048328093], [81, 0.018414408318769053], [23, 0.01855423292698453], [65, 0.01938015376792324], [63, 0.02072357465345583], [20, 0.021790755304662058], [53, 0.02276350267289312], [82, 0.02276350267289312], [16, 0.02290423393638406], [57, 0.02314153090270996], [60, 0.025506734601298067], [85, 0.026506672551624012], [4, 0.026776598006371596], [52, 0.02875624185606008], [33, 0.029771105220749935], [39, 0.03272415197791791], [35, 0.03474444587731039], [74, 0.03516923213492263], [95, 0.03619371899705285], [9, 0.036964343459406385], [32, 0.03825148766413921], [56, 0.038419708694368], [54, 0.04099970999194341], [28, 0.04188519939530096], [40, 0.04274007060099563], [67, 0.04308299225619573], [84, 0.04778086744774244], [55, 0.04792120338678286], [15, 0.05874255298632514], [43, 0.06456145652832253], [42, 0.06523361506981556], [44, 0.0718129201952091], [18, 0.0734118489185981], [50, 0.0746432837272482], [70, 0.0833831411688578], [5, 0.09242787376436135], [26, 0.10626330835933472], [73, 0.1691239130668874], [2, 0.1742484008668953], [94, 0.2213944349675946], [48, 0.22858209077708355], [51, 0.2896896466976147], [13, 0.32340527048097106], [96, 0.3627963538030673]]\n"
     ]
    }
   ],
   "source": [
    "#now provide a list of index ranked by relevence\n",
    "temp = [[i , similarity[0][i - 1]] for i in range(1 , 101)]\n",
    "print(temp)\n",
    "sorted_temp = sorted(temp, key=lambda x: x[1])\n",
    "print(sorted_temp)\n",
    "\n",
    "first , second , third = sorted_temp[-1][0] , sorted_temp[-2][0] , sorted_temp[-3][0]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "681fecd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Industrial output falls in Japan  Japanese industrial output fell in October while unemployment rose, casting further doubt on the strength of the country's economic recovery.  Production dropped 1.6% in October, reflecting a decline in exports, while unemployment levels edged up 0.1% to 4.7%, slightly higher than forecast. The economy has grown for six quarters but growth slowed dramatically in the last quarter amid weaker global demand. Japan's government remains optimistic due to strong domestic demand.  Analysts had been forecasting a 0.1% rise in month on month industrial output.  According to figures from the Ministry of Economy, Trade and Industry (METI), the decline was led by a fall in demand for electronic parts for mobile phones and digital televisions. Although inventories fell 0.7% month on month, they were 36% higher than a year ago. \"It's a sign that the economy's adjustment phase is stronger than expected,\" said Takashi Yamanaka, an economist with UFJ Bank. Japan downgraded its overall economic assessment earlier this month for the first time in a year.  Growth slowed to 0.3% in the quarter ending September 30, down from 6.3% in the first quarter of 2004. Experts believe the economy -which stagnated for most of the 1990s -may be entering a softer patch on the back of rising oil prices and the falling dollar. Japanese government officials played down the latest data, arguing that domestic consumer demand was still resilient. \"The outlook for November is positive so I don't think one can say that conditions have worsened just because of the fall in October,\" said a METI official. Despite the rise in unemployment, jobless figures are still some way below historical highs of recent years. The comparatively weak economic date preyed on shares with the Nikkei down 1% in afternoon trade. \n"
     ]
    }
   ],
   "source": [
    "print(docs[first - 1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
